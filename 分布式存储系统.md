[TOC]



# DMS（Paas）

## 高可用

### 双写（占网络带宽）

### 备选一，异步备份（类 mysql）

### 备选二，同步备份（太慢）

|      | 双写             | 异步备份                                                     | 同步备份               |
| ---- | ---------------- | ------------------------------------------------------------ | ---------------------- |
| 缺   | 占double网络带宽 | 存在丢数据（主写完，备没写完，这时主宕机数据会丢失，但已给客户返回了上传成功。mysql 如何做的？） | 太慢，客户等写两遍磁盘 |
| 优   |                  |                                                              |                        |

## 扩展性（Rebalance）

加机器，会产生写热点问题。解决办法是：新加入的机器先从其余机器拷贝数据过来使其达到平均数据量，再启用。

## Why DMS

* 存在一机上传，多机访问的需求，**对象存储**可以做到数据共享，但缺少文件系统接口，比如获取目录下所有文件等接口，不方便开发。**块存储**可以文件系统访问，但不支持共享。对象存储和块存储？
* 后序针对大数据分析，可能会基于分布式文件系统做特征提取，文件系统等并发和吞吐直接影响效率



## 其他问题

### 检验和（HighwayHash，存在数据库？）

## 遇到的问题及排查解决

### 死锁

查询存在就更新，不存在就插入，在事务中查询得是当前读，因此先 select for update 不存在再插入。事务1（以下简称为T1）与事务2（以下简称为T2）同时持有间隙锁(20, 30)后（间隙锁允许同时持有），然T1又想插入21时被T2阻塞，T2想插入22时被T1阻塞。

### mysql主备数据不一致

### mixed模式导入数据（自增id）执行计划是statement，导致主从 id 不一致

主从执行计划不一致原因是，表连接优化器在主上选择是先 a 后 b，在从上是先 b 后 a，导致索引走的不一样。

解决方案？

### 大事务引发的问题

1. 主从延迟增大（事务提交才会写入binlog）

### todo

- [ ] 列出上传下载速率指标，几台机器，多大文件，多块速率读写 
- [ ] minio高可用：erasure code，highway hash，reed-solomon code。n 份原始数据 + m 份备份数据，能通过 n+m 中的任意 n 份数据还原数据。todo 查论文。
- [ ] 垃圾 chunk 回收

### Why

* 应用错误、os错误、人为错误、磁盘、内存、网络故障、掉电。因此持续监控、容错、错误恢复是该系统的初衷。
* 高可用性，down 机
* 单机性能瓶颈
* 扩容（动态添加 group）
* 容错性（同一组，各机器互为备份）
* 允许多台计算机共享和访问文件

举例：HDFS，GFS(Google File System), Ceph

### What

文件存储、文件同步、文件下载

coor 是对等的。

同一 group 内容相同，不同 group 内容不同。

group 内剩余容量，以最小的机器为准，因此建议机器配置相同，以免浪费。

### 问题

* group 内增加机器，自动同步，同步完成后，系统自动将新增的服务器切换至线上提供服务。如何实现的
* 扩容，动态添加 group，如何实现的
* 一台机器down，如何自动切换，并提醒
* 如何处理并发访问
* 负载均衡，不同 group 剩余存储最大优先？
* 多个 coor 如何工作，挂了如何切换？
* coor、contentserver，可随时加入、退出，原理是什么？
* 上传失败，如何处理；
* 断点续传

### 遇到的印象深刻的问题并如何解决

从 issue 中找

### 考点

* 同一组内，上传完一台机器即为成功，后台线程同步至其他机器；写文件同时，写 binlog，只记录元数据，用于后台同步（？）。
* 如何处理并发访问？
  * 同一时间只有一个客户端能够修改文件：文件锁、乐观锁、分布式锁
  * coor 处理文件锁，一台 coor 会有单点故障问题，多台有同步问题？
* 如何处理网络中的丢包和超时？
  - 可以使用超时机制来检测丢包和超时情况，并根据具体情况进行重传或重新请求。此外，可以实现一些错误检测和纠正机制，如使用校验和或冗余数据等。
* 如何实现负载均衡和故障恢复？
  - 负载均衡可以通过在分布式文件系统中使用负载均衡算法，如轮询、随机选择或基于性能的选择来分发请求。故障恢复：**冗余存储**、故障转移策略。
* 数据传输协议？
  * HTTP？
* 如何确保分布式文件系统的安全性？
  * 可以采用多层次的安全措施，如身份验证、访问控制列表（ACL）、数据加密和安全传输协议（如TLS/SSL）。另外，定期进行安全审计和漏洞扫描也是保障系统安全的重要措施。
* 切片为什么是 4M？GFS = 64MB。依据：大块优：减少chunk数量，减少coor存储元数据数据量、减少client与coor交互的次数、client 缓存能缓存更多块meta；大块缺：小文件仅含一块，热门文件易造成热点机器。
* 垃圾回收。GFS 在删除时重命名为带删除标志和时间的名字，待定期全盘扫描chunk时，将带有删除标志且时间>3天(可配)的删除。
* 数据完整性 -- highwayhash 校验和
* 高可用。coor 做几个 replica 平时不用，一旦 master down 立即使用；contentserver 也做replica。
* 遇到的问题：磁盘与Linux驱动不匹配，导致有些文件损坏，因此要加上校验和。
* DMS 中的CAP，选的是CP，强一致性，保证数据安全。（同步复制技术会满足数据的强一致性，但会牺牲一定的可用性；异步复制技术会满足高可用，但一定程度上牺牲了数据的一致性）

### Key

* 不同的块可以被存储在不同的存储节点上，以实现数据的并行读写和负载均衡
*   * minio高可用：erasure code，highway hash，reed-solomon code。n 份原始数据 + m 份备份数据，能通过 n+m 中的任意 n 份数据还原数据。todo 查论文。

### HighwayHash

利用现代计算机的 SIMD（Single Instruction, Multiple Data）架构，利用计算机硬件的并行性和数据并行性，通过同时处理多个数据块来加速哈希计算。

md5(message digest algorithm 5, 128-bit)：弱hash

SHA-256(secure hash algorithm 256-bit)：强hash

源码：利用一些与或非异或操作和移位操作，将每4字节（传入的key: a0,a1,a2,a3）与固定的4字节进行逻辑操作得到hash值。

底层使用 SIMD 指令，一次操作多个数据，加快速度。

### SIMD

Single Instruction Multi Data 一条指令处理多条数据。有点像向量（矩阵）运算。

![img](http://ftp.cvut.cz/kernel/people/geoff/cell/ps3-linux-docs/CellProgrammingTutorial/CellProgrammingTutorial.files/image008.jpg)

### 分布式知识点

#### 选主算法

如果每个节点都可以写数据，这样容易造成数据的不一致，所以需要选举一个leader，往leader节点中写数据，然后同步到follower节点中。这样就能更好的保证一致性。

##### Raft算法

##### Bully 算法

![img](https://static001.geekbang.org/resource/image/fc/b8/fc0f00a3b7c9290bc91cb4d8721dc6b8.png?wh=571*378)

##### ZAB(zookeeper atomic broadcast) 算法

#### 分布式事务

2PC（2 Phase Commit），eg. mysql 

#### 分布式锁

##### 基于数据库

##### 基于内存

### 可靠性（Reed-solomon codes）

SEC-DED(Single Error Correcting - Double Error Detect)







